{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb309f84-6b18-40af-bc45-5400470b0b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # Delo z matriki z CPU/GPU podporo\n",
    "from torchvision import datasets, transforms # Predprocesiranje slik\n",
    "from torch.utils.data import DataLoader # Obravnava podatkov po manjših sklopih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51b306b8-6c64-413d-8a30-2109db6b6e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../Data/Podatki_split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cee53ed-2786-4b4e-88c3-d7d2189c82bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicija transofrmacije za konsistentnost podatkov (CNN želi 224x224, normalizacija)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d0ae5ce-ec30-44d6-b70d-e20261a17519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naloži slike iz map\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=f'{data_dir}/timeofday/train', transform=transform)\n",
    "val_dataset   = datasets.ImageFolder(root=f'{data_dir}/timeofday/val', transform=transform)\n",
    "test_dataset  = datasets.ImageFolder(root=f'{data_dir}/timeofday/test', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0aa49d75-0948-4338-8c01-aad9a2b9707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Razdeli slike po sklopih, boljša učinkovitost\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82424dcb-5ebc-409d-bc1f-3dc145aebb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oznake/Labels: ['day', 'night']\n",
      "Število slik v učnem sklopu: 6430\n"
     ]
    }
   ],
   "source": [
    "print(\"Oznake/Labels:\", train_dataset.classes)\n",
    "print(\"Število slik v učnem sklopu:\", len(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e6676-c033-44cc-8e7c-e7d7e81ee4b4",
   "metadata": {},
   "source": [
    "#### Training a Classifier: https://docs.pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "##### Docs: https://www.geeksforgeeks.org/introduction-convolution-neural-network/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e987f2c8-6e58-4930-a08d-4a39eccc1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32e88462-7fc4-413b-abf3-69583561f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeOfDayCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TimeOfDayCNN, self).__init__()\n",
    "\n",
    "        # Dve konvolucijske plasti\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "\n",
    "        # Popolnoma povezana/Fully connected plast\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "        \n",
    "    def forward(self, x): # Pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 56 * 56)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e4581-07fa-4841-95ab-803a97dc0c4c",
   "metadata": {},
   "source": [
    "#### Testiranje obnašanja podatkov v modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab949ea7-14f3-4c3a-b858-a4ce0e174527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oblika vhodnih slik: torch.Size([32, 3, 224, 224])\n",
      "Oznake: tensor([1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1])\n",
      "Oblika izhoda modela: torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "model = TimeOfDayCNN().to(device)\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "print(\"Oblika vhodnih slik:\", images.shape)\n",
    "print(\"Oznake:\", labels)\n",
    "\n",
    "images = images.to(device)\n",
    "outputs = model(images)\n",
    "\n",
    "print(\"Oblika izhoda modela:\", outputs.shape)  # želim [32, 2] za 32 slik in 2 različne oznake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6798c53c-9d50-4a3f-b517-8f51e69be869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss funkcija in optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597176e1-2e7a-4074-a1b9-389adc69b4e0",
   "metadata": {},
   "source": [
    "#### Treniranje in validacija mreže"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07ebac41-b036-4a55-8a90-4177e298f324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, validation_loader, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in validation_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = running_loss / len(validation_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5e9d8e7-f06c-4fc5-ba88-2fbaa8e283c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|████████████████████████████████████████████████████████| 201/201 [02:25<00:00,  1.38it/s, Loss=0.129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 - Training Loss: 0.1287, Validation Loss: 0.0523, Validation Accuracy: 99.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|███████████████████████████████████████████████████████| 201/201 [01:53<00:00,  1.77it/s, Loss=0.0523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 - Training Loss: 0.0523, Validation Loss: 0.0484, Validation Accuracy: 98.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|███████████████████████████████████████████████████████| 201/201 [01:56<00:00,  1.73it/s, Loss=0.0418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 - Training Loss: 0.0418, Validation Loss: 0.0665, Validation Accuracy: 98.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|███████████████████████████████████████████████████████| 201/201 [01:53<00:00,  1.77it/s, Loss=0.0206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 - Training Loss: 0.0206, Validation Loss: 0.0712, Validation Accuracy: 98.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|████████████████████████████████████████████████████████| 201/201 [01:49<00:00,  1.83it/s, Loss=0.014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 - Training Loss: 0.0140, Validation Loss: 0.0653, Validation Accuracy: 98.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|██████████████████████████████████████████████████████| 201/201 [01:49<00:00,  1.83it/s, Loss=0.00379]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 - Training Loss: 0.0038, Validation Loss: 0.0952, Validation Accuracy: 99.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|█████████████████████████████████████████████████████| 201/201 [01:49<00:00,  1.83it/s, Loss=0.000399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 - Training Loss: 0.0004, Validation Loss: 0.1032, Validation Accuracy: 98.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|█████████████████████████████████████████████████████| 201/201 [01:49<00:00,  1.84it/s, Loss=0.000124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 - Training Loss: 0.0001, Validation Loss: 0.1200, Validation Accuracy: 98.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|██████████████████████████████████████████████████████| 201/201 [01:52<00:00,  1.78it/s, Loss=6.07e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 - Training Loss: 0.0001, Validation Loss: 0.1231, Validation Accuracy: 98.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100%|█████████████████████████████████████████████████████| 201/201 [01:51<00:00,  1.80it/s, Loss=4.29e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 - Training Loss: 0.0000, Validation Loss: 0.1277, Validation Accuracy: 98.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100%|█████████████████████████████████████████████████████| 201/201 [01:48<00:00,  1.85it/s, Loss=3.25e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 - Training Loss: 0.0000, Validation Loss: 0.1297, Validation Accuracy: 98.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: 100%|█████████████████████████████████████████████████████| 201/201 [01:51<00:00,  1.80it/s, Loss=2.53e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 - Training Loss: 0.0000, Validation Loss: 0.1334, Validation Accuracy: 98.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: 100%|█████████████████████████████████████████████████████| 201/201 [01:51<00:00,  1.80it/s, Loss=2.06e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 - Training Loss: 0.0000, Validation Loss: 0.1358, Validation Accuracy: 98.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: 100%|█████████████████████████████████████████████████████| 201/201 [01:51<00:00,  1.80it/s, Loss=1.66e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 - Training Loss: 0.0000, Validation Loss: 0.1383, Validation Accuracy: 98.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|█████████████████████████████████████████████████████| 201/201 [01:49<00:00,  1.84it/s, Loss=1.37e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 - Training Loss: 0.0000, Validation Loss: 0.1405, Validation Accuracy: 98.91%\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 15 # Ni isto kot epizoda!, epoch - SL, episode - RL\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for images, labels in progress_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()                  # Tukaj se izvede backpropagation\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix({\"Loss\": running_loss / (progress_bar.n + 1)})\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # Validacija\n",
    "    val_loss, val_accuracy = validate(model, val_loader, criterion)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Training Loss: {avg_loss:.4f}, \"\n",
    "          f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c120253-f359-4e91-bce9-e466d997ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_daynight.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47fb0db-0e2c-4951-9318-6a2d3014eef0",
   "metadata": {},
   "source": [
    "#### Testiranje modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85141a7d-89d0-43e0-bd74-2a01604657e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimeOfDayCNN()\n",
    "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac115ba-6215-44a5-abbf-1233151a53d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef7eb01-b336-4a9c-af11-e9df9a07c030",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model, device, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
